# Environment Configuration
# Copy this file to .env and fill in your actual API keys and configuration

# ============================================================================
# REQUIRED - LLM API Keys (at least one provider required)
# ============================================================================

# Google Gemini API Key (RECOMMENDED - used for embeddings + chat)
# Get free key at: https://makersuite.google.com/app/apikey
# Free tier: 1,500 requests/day (sufficient for most use cases)
GEMINI_API_KEY=

# OpenRouter API Key (for DeepSeek and other models)
# Get key at: https://openrouter.ai/keys
# Pay-as-you-go: DeepSeek costs $0.14/1M tokens
OPENROUTER_API_KEY=

# OpenAI API Key (optional - for GPT models)
# Get key at: https://platform.openai.com/api-keys
OPENAI_API_KEY=


# ============================================================================
# REQUIRED - Database Configuration
# ============================================================================

# PostgreSQL connection string with asyncpg driver (required for vector support)
# Format: postgresql+asyncpg://username:password@host:port/database
# 
# Neon (serverless Postgres with pgvector):
#   DATABASE_URL=postgresql+asyncpg://user:pass@ep-xxx-pooler.region.aws.neon.tech/dbname
#
# Local Postgres (with pgvector extension installed):
#   DATABASE_URL=postgresql+asyncpg://postgres:password@localhost:5432/mydb
DATABASE_URL=


# ============================================================================
# REQUIRED - GitHub Configuration
# ============================================================================

# GitHub Personal Access Token
# Create at: https://github.com/settings/tokens
# Required scope: 
#   - repo (for private repos)
#   - public_repo (for public repos)
GITHUB_TOKEN=

# Target GitHub repository to index (full URL)
# Format: https://github.com/owner/repo-name
# Example: https://github.com/Pavankumar-Singh/sample_code_repo
GITHUB_TARGET_REPO=


# ============================================================================
# OPTIONAL - Ollama Configuration (for local models)
# ============================================================================

# Ollama base URL (uncomment if using local Ollama models)
# Default: http://localhost:11434
# OLLAMA_BASE_URL=http://localhost:11434


# ============================================================================
# OPTIONAL - Advanced Configuration (use defaults if unsure)
# ============================================================================

# Embedding Configuration
# ----------------------
# Model used for generating code embeddings (default: gemini-embedding-001)
# EMBEDDING_MODEL=gemini-embedding-001

# Provider for embeddings: gemini | openai (default: gemini)
# EMBEDDING_PROVIDER=gemini

# Vector dimension size (default: 768 for Gemini, 1536 for OpenAI)
# WARNING: Changing this requires re-indexing and recreating code_chunks table
# EMBEDDING_DIM=768

# Retrieval Configuration
# -----------------------
# Enable hybrid retrieval (lexical + semantic search) (default: true)
# HYBRID_RETRIEVAL=true

# Enable vector search indexing and retrieval (default: true)
# ENABLE_EMBED_INDEX=true


# ============================================================================
# NOTES
# ============================================================================
#
# 1. NEVER commit .env file to version control (already in .gitignore)
# 2. At minimum, you need:
#    - GEMINI_API_KEY (for embeddings)
#    - DATABASE_URL (Postgres with pgvector)
#    - GITHUB_TOKEN (for fetching code)
#    - GITHUB_TARGET_REPO (repository to index)
# 3. For best results, use Neon (https://neon.tech) for free serverless Postgres with pgvector
# 4. Gemini free tier (1,500 requests/day) is sufficient for indexing repos with <50 files
# 5. To use local models, install Ollama (https://ollama.ai) and set OLLAMA_BASE_URL
